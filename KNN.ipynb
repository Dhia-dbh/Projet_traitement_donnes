{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bfa49c0-0a64-4617-b7f0-6329a0a4214b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0e6d720-a2c5-4285-850f-c5f598c0e083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('merged_dhia.csv')\n",
    "\n",
    "# Shuffle the data\n",
    "np.random.seed(1)\n",
    "data = data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfdccf8f-ac1f-4881-b142-a8f4d652e436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the `processed_quotes` column from string to list\n",
    "data['processed_quotes'] = data['processed_quotes'].apply(eval)\n",
    "\n",
    "# Convert lists of tokens back into text for vectorization\n",
    "data['text_data'] = data['processed_quotes'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Convert categories into numerical labels (if not already numeric)\n",
    "data['Category'] = data['Category'].astype('category').cat.codes\n",
    "\n",
    "# Split the dataset\n",
    "train_one, test_one = train_test_split(data, test_size=0.2, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f6162c5-e2ca-492e-b311-14f133b9a0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the `text_data` column\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_one['text_data'])\n",
    "X_test = vectorizer.transform(test_one['text_data'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc6f95a2-734a-4f17-a793-e7795cc4146a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target column\n",
    "y_train = train_one['Category']\n",
    "y_test = test_one['Category']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "075973e6-a857-43fc-88ee-a8cf27ba7c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=1, algorithm='auto')\n",
    "knn.fit(X_train, y_train)  # Use dense data\n",
    "predictions = knn.predict(X_test)\n",
    "            \n",
    "# Convert predictions to integer classes\n",
    "predicted_classes = np.rint(predictions).astype(int)\n",
    "predicted_classes = np.clip(predicted_classes, 0, data['Category'].max())\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e7f8d5c-993e-4993-812a-b9eb9e41b587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        12\n",
      "           3       1.00      0.07      0.13        14\n",
      "           4       0.00      0.00      0.00        19\n",
      "           5       0.00      0.00      0.00         7\n",
      "           6       0.76      0.83      0.79        30\n",
      "           8       0.26      0.45      0.33        20\n",
      "           9       0.00      0.00      0.00         5\n",
      "          10       1.00      0.20      0.33        10\n",
      "          12       0.96      0.98      0.97       107\n",
      "          13       0.17      0.10      0.12        10\n",
      "          14       0.72      0.46      0.56        46\n",
      "          15       0.45      0.57      0.51        35\n",
      "          16       0.83      0.91      0.87        94\n",
      "          17       0.56      0.43      0.49        21\n",
      "          18       0.16      0.19      0.17        21\n",
      "          19       0.90      0.62      0.73       105\n",
      "          20       0.73      0.85      0.79        48\n",
      "          21       0.06      0.11      0.08        55\n",
      "          22       0.85      0.54      0.66        85\n",
      "          23       0.55      0.80      0.65        71\n",
      "          24       0.38      0.35      0.36        17\n",
      "          25       0.73      0.40      0.52        20\n",
      "          26       0.18      0.21      0.19        38\n",
      "          27       0.71      0.71      0.71        78\n",
      "          28       0.06      0.06      0.06        34\n",
      "          29       0.69      0.51      0.59        43\n",
      "          30       0.81      0.81      0.81       112\n",
      "          31       0.88      0.52      0.65        56\n",
      "          32       0.00      0.00      0.00         3\n",
      "          33       0.00      0.00      0.00         4\n",
      "          34       0.00      0.00      0.00        17\n",
      "          35       0.71      0.56      0.63        66\n",
      "          36       0.70      0.79      0.74       112\n",
      "          37       0.75      0.32      0.44        19\n",
      "          38       0.64      0.30      0.41        30\n",
      "          39       0.00      0.00      0.00         2\n",
      "          40       0.33      0.11      0.17         9\n",
      "          41       0.50      0.10      0.17        10\n",
      "          44       0.75      0.49      0.59        68\n",
      "          45       1.00      0.08      0.14        13\n",
      "          46       0.50      0.46      0.48        24\n",
      "          47       0.62      0.67      0.65        46\n",
      "          48       0.00      0.30      0.01        10\n",
      "          49       0.91      0.81      0.86        75\n",
      "          50       0.58      0.25      0.35        56\n",
      "          51       0.00      0.00      0.00         1\n",
      "          52       0.38      0.24      0.30        75\n",
      "          53       0.25      0.08      0.12        12\n",
      "          54       0.69      0.62      0.65        71\n",
      "          56       0.85      0.48      0.61        23\n",
      "          57       0.72      0.66      0.69       162\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.67      0.45      0.54       107\n",
      "          60       0.97      0.67      0.79        45\n",
      "          61       0.00      0.00      0.00         3\n",
      "          62       0.71      0.17      0.27        60\n",
      "          63       0.00      0.00      0.00         8\n",
      "          64       0.40      0.34      0.37        67\n",
      "          65       0.78      0.53      0.63       117\n",
      "          66       0.61      0.35      0.44        40\n",
      "          67       0.78      0.69      0.73        74\n",
      "          68       0.00      0.00      0.00         5\n",
      "          69       0.68      0.72      0.70       186\n",
      "          70       0.00      0.00      0.00         3\n",
      "          71       0.00      0.00      0.00         2\n",
      "          72       0.45      0.55      0.49        97\n",
      "          73       0.68      0.57      0.62        30\n",
      "          74       0.60      0.61      0.60        79\n",
      "          75       0.84      0.72      0.78        87\n",
      "          76       0.22      0.27      0.24        15\n",
      "          77       0.82      0.62      0.71        90\n",
      "          78       0.72      0.46      0.57        28\n",
      "          79       0.00      0.00      0.00         7\n",
      "          80       0.26      0.13      0.18        38\n",
      "          82       0.33      0.12      0.18        16\n",
      "          83       0.00      0.00      0.00         4\n",
      "          84       0.91      0.75      0.82        40\n",
      "          85       1.00      0.25      0.40         8\n",
      "          87       0.00      0.00      0.00         3\n",
      "          88       0.36      0.19      0.25        21\n",
      "          89       0.00      0.00      0.00         4\n",
      "          90       0.00      0.00      0.00         5\n",
      "          91       0.56      0.43      0.48        70\n",
      "          92       0.00      0.00      0.00        20\n",
      "          93       0.00      0.00      0.00        19\n",
      "          94       0.73      0.54      0.62        56\n",
      "          95       0.60      0.38      0.46        16\n",
      "          96       0.92      0.62      0.74        39\n",
      "          98       0.96      0.61      0.75        36\n",
      "          99       0.68      0.66      0.67        70\n",
      "         100       0.25      0.14      0.18         7\n",
      "         101       0.62      0.36      0.46        22\n",
      "         102       0.41      0.24      0.31        37\n",
      "         103       0.56      0.58      0.57        69\n",
      "         104       0.52      0.36      0.42        39\n",
      "         105       0.46      0.15      0.23        39\n",
      "         106       0.00      0.00      0.00         3\n",
      "         107       0.88      0.70      0.78        54\n",
      "         108       0.00      0.00      0.00         2\n",
      "         109       0.21      0.29      0.25        24\n",
      "         110       0.33      0.10      0.15        10\n",
      "         111       0.88      0.58      0.70        26\n",
      "         112       0.85      0.50      0.63        22\n",
      "         113       0.00      0.00      0.00         4\n",
      "         114       0.73      0.63      0.68        35\n",
      "         115       0.03      0.12      0.05        24\n",
      "         116       0.89      0.79      0.84        43\n",
      "         117       0.81      0.73      0.77        83\n",
      "         118       0.67      0.24      0.35        17\n",
      "         119       0.82      0.28      0.42        32\n",
      "         120       1.00      0.74      0.85        19\n",
      "         121       0.56      0.27      0.37        66\n",
      "         122       0.62      0.57      0.59        14\n",
      "         123       0.00      0.00      0.00         1\n",
      "         124       1.00      0.40      0.57         5\n",
      "         125       0.65      0.61      0.63        28\n",
      "         126       0.64      0.68      0.66        73\n",
      "         127       1.00      0.40      0.57         5\n",
      "         128       0.00      0.00      0.00        13\n",
      "         129       0.67      0.15      0.25        26\n",
      "         130       0.83      0.36      0.50        28\n",
      "         131       0.00      0.00      0.00        11\n",
      "         132       0.33      0.38      0.36        21\n",
      "         133       0.00      0.00      0.00        10\n",
      "         134       0.71      0.43      0.53        28\n",
      "\n",
      "    accuracy                           0.52      4677\n",
      "   macro avg       0.48      0.35      0.38      4677\n",
      "weighted avg       0.64      0.52      0.56      4677\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\asus\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\asus\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, predicted_classes)\n",
    "\n",
    "print(classification_report(y_test, predicted_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
